{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6944d30-369c-4ab2-807a-5bae53dc98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbbae7ad-7e96-417a-b479-a5d55804d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath, device=None):\n",
    "    \"\"\"\n",
    "    Load a ResNet-50 checkpoint for inference.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    # Load checkpoint (allow loading non-weights-only checkpoint)\n",
    "    checkpoint = torch.load(filepath, map_location=device, weights_only=False)\n",
    "\n",
    "\n",
    "    # Rebuild ResNet-50\n",
    "    model = models.resnet50(pretrained=False)\n",
    "\n",
    "    # Determine number of classes (support older checkpoints without 'num_classes')\n",
    "    num_classes = checkpoint.get('num_classes', None)\n",
    "    if num_classes is None:\n",
    "        num_classes = len(checkpoint.get('class_to_idx', []))\n",
    "\n",
    "    # Rebuild final fully connected layer\n",
    "    model.fc = nn.Linear(\n",
    "        model.fc.in_features,\n",
    "        num_classes\n",
    "    )\n",
    "\n",
    "    # Load trained weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # Restore class mapping\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeb71fd2-c294-4231-8520-f8389aec3941",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: \"'/Users/monaverma/Documents/image classifiers/finetune_resnet/cat_to_name.json'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load the mapping file located next to this script\u001b[39;00m\n\u001b[32m      4\u001b[39m cat_file = \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m/Users/monaverma/Documents/image classifiers/finetune_resnet/cat_to_name.json\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcat_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      7\u001b[39m     cat_to_name = json.load(f)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# cat_file = os.path.join(os.path.dirname(__file__), 'cat_to_name.json')\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# with open(cat_file, 'r') as f:\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#     cat_to_name = json.load(f)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: \"'/Users/monaverma/Documents/image classifiers/finetune_resnet/cat_to_name.json'\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Load the mapping file located next to this script\n",
    "cat_file = \"'/Users/monaverma/Documents/image classifiers/finetune_resnet/cat_to_name.json'\"\n",
    "\n",
    "with open(cat_file, 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "# cat_file = os.path.join(os.path.dirname(__file__), 'cat_to_name.json')\n",
    "# with open(cat_file, 'r') as f:\n",
    "#     cat_to_name = json.load(f)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"Scales, crops, and normalizes a PIL image for a PyTorch model.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    image = preprocess(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae652b-3fa0-47dc-8f3b-fa24fa8cd80f",
   "metadata": {},
   "source": [
    "# Assistant\n",
    "The error occurs because the file path has extra quotes inside the string, which makes Python look for a file with those quotes in the filename.\n",
    "\n",
    "Explanation:\n",
    "When you define `cat_file`, you're using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c40ac08-7ceb-4b80-b2b7-d5b346d5e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_file = \"'/Users/monaverma/Documents/image classifiers/finetune_resnet/cat_to_name.json'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce57c2-c83a-4404-98ca-6193c3f1cded",
   "metadata": {},
   "source": [
    "\n",
    "This creates a string that literally includes the single quotes, so Python is looking for a file named:\n",
    "`'/Users/monaverma/Documents/image classifiers/finetune_resnet/cat_to_name.json'` (with the quotes)\n",
    "\n",
    "Would you like me to provide the corrected code?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a33d4-3e27-4bc7-9fee-7447da1aa84f",
   "metadata": {},
   "source": [
    "# User\n",
    "yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341de7f4-08b6-4045-8366-13d37e18697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assistant\n",
    "import os\n",
    "import json  # Added import for json module\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms  # Added import for transforms\n",
    "\n",
    "# Load the mapping file located next to this script\n",
    "# Remove the extra quotes inside the string\n",
    "cat_file = \"/Users/monaverma/Documents/image classifiers/finetune_resnet/cat_to_name.json\"\n",
    "\n",
    "with open(cat_file, 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "\n",
    "# cat_file = os.path.join(os.path.dirname(__file__), 'cat_to_name.json')\n",
    "# with open(cat_file, 'r') as f:\n",
    "#     cat_to_name = json.load(f)\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"Scales, crops, and normalizes a PIL image for a PyTorch model.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    image = preprocess(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b63fb9f-8f51-4bd1-86d9-5a75fcd472ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    model.eval()\n",
    "    image = process_image(image_path)\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logps = model(image)\n",
    "        # Convert logits to probabilities\n",
    "        ps = torch.nn.functional.softmax(logps, dim=1)\n",
    "        top_p, top_class = ps.topk(topk, dim=1)\n",
    "\n",
    "    top_p = top_p.cpu().numpy().squeeze().tolist()\n",
    "    top_class = top_class.cpu().numpy().squeeze().tolist()\n",
    "    idx_to_class = {v : k for k, v in model.class_to_idx.items()}\n",
    "    top_classes = [idx_to_class[i] for i in top_class]\n",
    "    return top_p, top_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26069360-99bb-46e0-9186-eac335d246c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad8bc133-b6ee-4897-84f0-11a6ac52a645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m checkpoint_path = \u001b[33m'\u001b[39m\u001b[33m/Users/monaverma/Documents/image classifiers/finetune_resnet/checkpoint_resnet_finetune.pth\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# Replace with your checkpoint path\u001b[39;00m\n\u001b[32m      6\u001b[39m model = load_checkpoint(checkpoint_path)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model.to(\u001b[43mdevice\u001b[49m)\n\u001b[32m      9\u001b[39m image_path = \u001b[33m'\u001b[39m\u001b[33mflower_data/test/43/image_02369.jpg\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# Replace with your image path\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(image_path):\n",
      "\u001b[31mNameError\u001b[39m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Plot top K predictions as a horizontal bar chart\n",
    "\n",
    "    checkpoint_path = '/Users/monaverma/Documents/image classifiers/finetune_resnet/checkpoint_resnet_finetune.pth'  # Replace with your checkpoint path\n",
    "    model = load_checkpoint(checkpoint_path)\n",
    "    model.to(device)\n",
    "\n",
    "    image_path = 'flower_data/test/43/image_02369.jpg'  # Replace with your image path\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image not found: {image_path}\\nPlease update `image_path` in resnet_predict.py to point to a valid image.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    top_p, top_classes = predict(image_path, model, topk=5)\n",
    "\n",
    "    # Map the top predicted class ids to human-readable names\n",
    "    top_flower_names = [cat_to_name[cls] for cls in top_classes]\n",
    "\n",
    "    print(\"Top Probabilities:\", top_p)\n",
    "    print(\"Top Classes:\", top_classes)\n",
    "    print(\"Top Flower Names:\", top_flower_names)\n",
    "\n",
    "# Convert probabilities to percentages\n",
    "top_p_percent = [p * 100 for p in top_p]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.barh(top_flower_names[::-1], top_p_percent[::-1], color='skyblue')  # reverse to have highest on top\n",
    "plt.xlabel('Probability (%)')\n",
    "plt.title('Top 5 Predicted Flowers')\n",
    "plt.xlim(0, 100)\n",
    "\n",
    "# Show probability values on bars\n",
    "for i, v in enumerate(top_p_percent[::-1]):\n",
    "    plt.text(v + 1, i, f\"{v:.1f}%\", color='blue', va='center', fontweight='bold')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "    # Display the image\n",
    "image = process_image(image_path)\n",
    "imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5891b82-09ed-4940-ab50-a5f2cd56148c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
